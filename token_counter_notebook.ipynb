{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39284a43",
   "metadata": {},
   "source": [
    "# Token Counter Notebook\n",
    "\n",
    "This notebook allows you to input text, retrieve outputs, and calculate token counts using OpenAI, Gemini, Anthropic, and Grok APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f2b80",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries\n",
    "\n",
    "Install necessary libraries such as `openai`, `anthropic`, and others. Import required modules like `os` and `json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e441ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (uncomment if running for the first time)\n",
    "# !pip install openai anthropic google-generativeai requests\n",
    "\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import anthropic\n",
    "from google import genai\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311df612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.jp-OutputArea-output { max-width: 100vw !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make output cells take full width\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.jp-OutputArea-output { max-width: 100vw !important; }</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c8ca06",
   "metadata": {},
   "source": [
    "## 2. Set Up API Keys\n",
    "\n",
    "Set up environment variables or directly define API keys for OpenAI, Gemini, Anthropic, and Grok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "638367d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API keys here or load them from environment variables\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-openai-api-key\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\", \"your-anthropic-api-key\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"your-gemini-api-key\")\n",
    "GROK_API_KEY = os.getenv(\"GROK_API_KEY\", \"your-grok-api-key\")\n",
    "\n",
    "# Set API keys for respective libraries if possible\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3a11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your user prompt here\n",
    "prompt = 'hello'\n",
    "\n",
    "# Enter your system prompt here\n",
    "system_prompt = ''\n",
    "\n",
    "# Enter the number of trials to run\n",
    "num_trials = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df72b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_openai_chat(prompt, system_prompt, model=\"gpt-4o\"):\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        output = response.choices[0].message.content\n",
    "        input_tokens = getattr(response.usage, 'prompt_tokens', None)\n",
    "        output_tokens = getattr(response.usage, 'completion_tokens', None)\n",
    "        return output, input_tokens, output_tokens\n",
    "    except Exception as e:\n",
    "        return f\"OpenAI ChatCompletions error: {str(e)}\", None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bab4cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_gemini(prompt, system_prompt, model=\"gemini-2.0-flash\"):\n",
    "    try:\n",
    "        from google import genai\n",
    "        from google.genai import types\n",
    "        client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "            contents=prompt\n",
    "        )\n",
    "        output = getattr(response, 'text', str(response))\n",
    "        usage = getattr(response, 'usage_metadata', None)\n",
    "        input_tokens = usage.prompt_token_count if usage and hasattr(usage, 'prompt_token_count') else None\n",
    "        output_tokens = usage.candidates_token_count if usage and hasattr(usage, 'candidates_token_count') else None\n",
    "        return output, input_tokens, output_tokens\n",
    "    except Exception as e:\n",
    "        return f\"Gemini error: {str(e)}\", None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5d98dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_anthropic(prompt, system_prompt, model=\"claude-3-7-sonnet-20250219\"):\n",
    "    try:\n",
    "        import anthropic\n",
    "        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n",
    "        message = client.messages.create(\n",
    "            model=model,\n",
    "            max_tokens=1024,\n",
    "            system=system_prompt,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        output = message.content[0].text if hasattr(message.content[0], 'text') else str(message.content[0])\n",
    "        input_tokens = getattr(message.usage, 'input_tokens', None)\n",
    "        output_tokens = getattr(message.usage, 'output_tokens', None)\n",
    "        return output, input_tokens, output_tokens\n",
    "    except Exception as e:\n",
    "        return f\"Anthropic error: {str(e)}\", None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664cd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_with_grok(prompt, system_prompt, model=\"grok-3-beta\"):\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI(\n",
    "            api_key=GROK_API_KEY,\n",
    "            base_url=\"https://api.x.ai/v1\",\n",
    "        )\n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        completion = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages\n",
    "        )\n",
    "        output = completion.choices[0].message.content\n",
    "        input_tokens = getattr(completion.usage, 'prompt_tokens', None)\n",
    "        output_tokens = getattr(completion.usage, 'completion_tokens', None)\n",
    "        return output, input_tokens, output_tokens\n",
    "    except Exception as e:\n",
    "        return f\"Grok error: {str(e)}\", None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c008eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run Number</th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Model</th>\n",
       "      <th>User Prompt</th>\n",
       "      <th>System Prompt</th>\n",
       "      <th>Output</th>\n",
       "      <th>Input Tokens</th>\n",
       "      <th>Output Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello there! How can I help you today?\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today? I'm here to...</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Grok</td>\n",
       "      <td>grok-3-beta</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hey there! How can I help you today? ðŸ˜Š</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello there! How can I help you today?\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today? I'm here to...</td>\n",
       "      <td>8</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>Grok</td>\n",
       "      <td>grok-3-beta</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hey there! How can I help you today?</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>gpt-4o</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I assist you today?</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>Gemini</td>\n",
       "      <td>gemini-2.0-flash</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I help you today?\\n</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>claude-3-7-sonnet-20250219</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hello! How can I help you today? I'm here to a...</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>Grok</td>\n",
       "      <td>grok-3-beta</td>\n",
       "      <td>hello</td>\n",
       "      <td></td>\n",
       "      <td>Hey there! How can I help you today?</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Run Number     Vendor                       Model User Prompt  \\\n",
       "0            1     OpenAI                      gpt-4o       hello   \n",
       "1            1     Gemini            gemini-2.0-flash       hello   \n",
       "2            1  Anthropic  claude-3-7-sonnet-20250219       hello   \n",
       "3            1       Grok                 grok-3-beta       hello   \n",
       "4            2     OpenAI                      gpt-4o       hello   \n",
       "5            2     Gemini            gemini-2.0-flash       hello   \n",
       "6            2  Anthropic  claude-3-7-sonnet-20250219       hello   \n",
       "7            2       Grok                 grok-3-beta       hello   \n",
       "8            3     OpenAI                      gpt-4o       hello   \n",
       "9            3     Gemini            gemini-2.0-flash       hello   \n",
       "10           3  Anthropic  claude-3-7-sonnet-20250219       hello   \n",
       "11           3       Grok                 grok-3-beta       hello   \n",
       "\n",
       "   System Prompt                                             Output  \\\n",
       "0                                Hello! How can I assist you today?   \n",
       "1                          Hello there! How can I help you today?\\n   \n",
       "2                 Hello! How can I assist you today? I'm here to...   \n",
       "3                            Hey there! How can I help you today? ðŸ˜Š   \n",
       "4                                Hello! How can I assist you today?   \n",
       "5                          Hello there! How can I help you today?\\n   \n",
       "6                 Hello! How can I assist you today? I'm here to...   \n",
       "7                              Hey there! How can I help you today?   \n",
       "8                                Hello! How can I assist you today?   \n",
       "9                                Hello! How can I help you today?\\n   \n",
       "10                Hello! How can I help you today? I'm here to a...   \n",
       "11                             Hey there! How can I help you today?   \n",
       "\n",
       "    Input Tokens  Output Tokens  \n",
       "0             12             10  \n",
       "1              1             11  \n",
       "2              8             36  \n",
       "3              7             13  \n",
       "4             12             10  \n",
       "5              1             11  \n",
       "6              8             40  \n",
       "7              7             11  \n",
       "8             12             10  \n",
       "9              1             10  \n",
       "10             8             31  \n",
       "11             7             11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results output to api_results.csv\n"
     ]
    }
   ],
   "source": [
    "all_rows = []\n",
    "for run in range(1, num_trials + 1):\n",
    "    results = {}\n",
    "    try:\n",
    "        output, in_tok, out_tok = process_with_openai_chat(prompt, system_prompt)\n",
    "        results['OpenAI'] = {'output': output, 'input_tokens': in_tok, 'output_tokens': out_tok, 'model': 'gpt-4o'}\n",
    "    except Exception as e:\n",
    "        results['OpenAI'] = {'output': str(e), 'input_tokens': None, 'output_tokens': None, 'model': 'gpt-4o'}\n",
    "    try:\n",
    "        output, in_tok, out_tok = process_with_gemini(prompt, system_prompt)\n",
    "        results['Gemini'] = {'output': output, 'input_tokens': in_tok, 'output_tokens': out_tok, 'model': 'gemini-2.0-flash'}\n",
    "    except Exception as e:\n",
    "        results['Gemini'] = {'output': str(e), 'input_tokens': None, 'output_tokens': None, 'model': 'gemini-2.0-flash'}\n",
    "    try:\n",
    "        output, in_tok, out_tok = process_with_anthropic(prompt, system_prompt)\n",
    "        results['Anthropic'] = {'output': output, 'input_tokens': in_tok, 'output_tokens': out_tok, 'model': 'claude-3-7-sonnet-20250219'}\n",
    "    except Exception as e:\n",
    "        results['Anthropic'] = {'output': str(e), 'input_tokens': None, 'output_tokens': None, 'model': 'claude-3-7-sonnet-20250219'}\n",
    "    try:\n",
    "        output, in_tok, out_tok = process_with_grok(prompt, system_prompt)\n",
    "        results['Grok'] = {'output': output, 'input_tokens': in_tok, 'output_tokens': out_tok, 'model': 'grok-3-beta'}\n",
    "    except Exception as e:\n",
    "        results['Grok'] = {'output': str(e), 'input_tokens': None, 'output_tokens': None, 'model': 'grok-3-beta'}\n",
    "    for vendor, res in results.items():\n",
    "        all_rows.append({\n",
    "            'Run Number': run,\n",
    "            'Vendor': vendor,\n",
    "            'Model': res['model'],\n",
    "            'User Prompt': prompt,\n",
    "            'System Prompt': system_prompt,\n",
    "            'Output': res['output'],\n",
    "            'Input Tokens': res['input_tokens'],\n",
    "            'Output Tokens': res['output_tokens']\n",
    "        })\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(all_rows)\n",
    "display(df)\n",
    "# Output all results to a CSV file\n",
    "csv_path = 'api_results.csv'\n",
    "df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "print(f'Results output to {csv_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "all_llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
